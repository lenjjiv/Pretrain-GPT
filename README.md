# –î–æ–æ–±—É—á–µ–Ω–∏–µ GPT-2 –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ

–ü—Ä–æ–µ–∫—Ç —Ä–µ–∞–ª–∏–∑—É–µ—Ç –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ GPT-2 –Ω–∞ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞ Alpaca.

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
üì¶ gpt2-ru-finetuning
 ‚î£ üìÇ src                    # –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥
 ‚îÉ ‚î£ üìú tokenizer.py        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
 ‚îÉ ‚î£ üìú dataset.py          # –†–∞–±–æ—Ç–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º
 ‚îÉ ‚î£ üìú model.py            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
 ‚îÉ ‚î£ üìú trainer.py          # –õ–æ–≥–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
 ‚îÉ ‚îó üìú generator.py        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
 ‚î£ üìÇ scripts               # –°–∫—Ä–∏–ø—Ç—ã
 ‚îÉ ‚îó üìú train.py            # –ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
 ‚î£ üìú requirements.txt      # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞
 ‚î£ üìú .gitignore           # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã–µ —Ñ–∞–π–ª—ã Git
 ‚îó üìú README.md            # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
```

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞

1. –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:
```bash
git clone https://github.com/your-username/gpt2-ru-finetuning.git
cd gpt2-ru-finetuning
```

2. –°–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ –∞–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –µ–≥–æ:
```bash
python -m venv venv
source venv/bin/activate  # –¥–ª—è Linux/MacOS
# –∏–ª–∏
venv\Scripts\activate     # –¥–ª—è Windows
```

3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
```bash
pip install -r requirements.txt
```

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

–î–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è:

```bash
python scripts/train.py
```

–≠—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω:
1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫—É —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–∏
3. –ó–∞–≥—Ä—É–∑–∫—É –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞
4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞:

```python
from src.generator import TextGenerator

generator = TextGenerator(
    model_path="./gpt2_finetuned_final",
    device=0  # –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ -1 –¥–ª—è CPU
)

text = generator.generate(
    prompt="some_text",
    max_length=100,
    temperature=0.8
)
print(text)
```

## –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è

–û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≤ `src/trainer.py`:

- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö: 5
- –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: 16
- –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è: 5e-5
- –®–∞–≥–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞: 10
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: 512 —Ç–æ–∫–µ–Ω–æ–≤

## –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

- –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: GPT-2
- –î–∞—Ç–∞—Å–µ—Ç: Alpaca Russian
- –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: 20,000 —Ç–æ–∫–µ–Ω–æ–≤
- –†–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: 384 (768/2)
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤: 12
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ–ª–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è: 12

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–¥–∞

- `tokenizer.py`: –°–æ–¥–µ—Ä–∂–∏—Ç –ª–æ–≥–∏–∫—É –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞, –≤–∫–ª—é—á–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Å–ª–æ–≤–∞—Ä—è –∏ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
- `dataset.py`: –†–µ–∞–ª–∏–∑—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞, –≤–∫–ª—é—á–∞—è –ø–æ—Ç–æ–∫–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö
- `model.py`: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏
- `trainer.py`: –°–æ–¥–µ—Ä–∂–∏—Ç –ª–æ–≥–∏–∫—É –æ–±—É—á–µ–Ω–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- `generator.py`: –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞